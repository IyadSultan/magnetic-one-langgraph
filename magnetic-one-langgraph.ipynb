{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magnetic-one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the workflow diagram of **Magnetic-One Multi-Agent System** presented in its article:\n",
    "\n",
    "### 1. Outer Loop – Initial Setup and Planning\n",
    "\n",
    "   - **Task Trigger**: The process begins when a prompt or task is initiated. This prompts the **Orchestrator**, the main coordinating agent, to set up a **Task Ledger**.\n",
    "   - **Task Ledger Creation**: The Task Ledger acts as a short-term memory for the task, recording key details that will guide the workflow.\n",
    "   - **Fact and Guess Collection**: The Orchestrator gathers and pre-populates the Task Ledger with known facts, information to look up, derivable data, and educated guesses to frame initial responses.\n",
    "   - **Plan Formation**: Using the Task Ledger and the capabilities of the available agents, the Orchestrator creates a **step-by-step plan**. This plan provides hints for task execution, guiding each agent in its respective role.\n",
    "   - **Inner Loop Initiation**: After establishing the plan, the Orchestrator starts the **Inner Loop**.\n",
    "\n",
    "### 2. Inner Loop – Iterative Task Execution and Monitoring\n",
    "\n",
    "   During each iteration of the inner loop, the Orchestrator:\n",
    "   \n",
    "   - **Evaluates Task Completion**: Checks if the task has been fully satisfied.\n",
    "   - **Checks for Loops or Stalls**: Monitors for repeated steps or a lack of forward progress.\n",
    "   - **Makes Adjustments**: If progress is slow or looping is detected, the **Counter** (a stalling indicator) is incremented.\n",
    "   - **Agent Selection and Instructions**: As long as progress continues or the Counter is within threshold limits, the Orchestrator selects the next agent to act and gives it specific instructions for the task at hand.\n",
    "   - **Reflection and Self-Refinement**: If the Counter exceeds the threshold, the Orchestrator pauses the inner loop, revisits its previous steps, updates the Task Ledger, and revises the plan. This self-reflection allows the system to adapt and correct any identified issues before resuming the inner loop.\n",
    "\n",
    "   The inner loop continues until the Orchestrator determines the task is complete or hits a predefined stopping criterion (e.g., maximum attempts or time limits).\n",
    "\n",
    "### 3. Agents – Specialized Task Execution\n",
    "\n",
    "   - **WebSurfer**: Manages interactions with a web browser, handling tasks like navigating websites, clicking, typing, or summarizing webpage content.\n",
    "   - **FileSurfer**: Focuses on navigating and reading files, such as PDFs and images, to retrieve necessary data.\n",
    "   - **Coder**: Develops, analyzes, or debugs code as needed for the task.\n",
    "   - **ComputerTerminal**: Executes code or installs libraries to support programming tasks, interacting with a console environment.\n",
    "\n",
    "   Each agent specializes in particular actions, and the Orchestrator directs agents as needed to accomplish the overall task.\n",
    "\n",
    "### 4. Termination and Final Reporting\n",
    "\n",
    "   - Once the task is complete or the termination conditions are met, both the outer and inner loops end.\n",
    "   - **Final Review and Report**: The Orchestrator reviews all progress records and the Task Ledger to produce either a final solution or its best educated guess if uncertainties remain.\n",
    "\n",
    "In summary, the workflow allows the Orchestrator to iteratively guide agents, adapt to challenges, and refine its approach in real time. This multi-layered control ensures robust task execution even in complex, dynamic environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Diagram\n",
    "\n",
    "The following diagram illustrates the workflow of the MagneticOne multi-agent system, breaking down the **Outer Loop**, **Inner Loop**, and **Agent** components. This visualization provides a structural overview of task progression, agent roles, and decision points within the system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MagneticOne Workflow Diagram](diagram_representation_workflow.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mermaid Chart Structure\n",
    "\n",
    "You can view the diagram directly and copy it to edit it using this [Mermaid Chart link](https://www.mermaidchart.com/app/projects/e0960e96-f27b-4905-b83b-a4741a09c128/diagrams/bcc71cc4-c0fe-4267-a797-99ec0491a8fb/version/v0.1/edit).\n",
    "\n",
    "In addition, here's the structure from Mermaid Chart: \n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    subgraph OuterLoop [\"Outer Loop\"]\n",
    "        Start[\"Initial Task Trigger\"]\n",
    "        Start -->|Creates| TaskLedger[\"Task Ledger\"]\n",
    "        TaskLedger -->|Pre-populates with| Facts[\"Facts, Lookups, Guesses\"]\n",
    "        Facts -->|Uses roles to form| Plan[\"Step-by-Step Plan\"]\n",
    "        Plan -->|Starts| InnerLoop\n",
    "    end\n",
    "\n",
    "    subgraph InnerLoop [\"Inner Loop\"]\n",
    "        InnerLoop -->|Evaluate| CheckTask{\"Is Task Complete?\"}\n",
    "        CheckTask -->|Yes| Terminate[Terminate]\n",
    "        CheckTask -->|No| ProgressCheck{\"Stalling or Looping?\"}\n",
    "        ProgressCheck -->|No| NextAgent[\"Choose Next Agent\"]\n",
    "        NextAgent --> InnerLoop\n",
    "        ProgressCheck -->|Yes| Counter[\"Increment Counter\"]\n",
    "        Counter -->|Exceeds Threshold| Reflect[\"Reflection & Self-Refinement\"]\n",
    "        Reflect --> UpdateLedger[\"Update Task Ledger and Plan\"]\n",
    "        UpdateLedger --> InnerLoop\n",
    "    end\n",
    "\n",
    "    subgraph Agents [\"Agents in Magnetic-One System\"]\n",
    "        Orchestrator -- Directs --> WebSurfer\n",
    "        Orchestrator -- Directs --> FileSurfer\n",
    "        Orchestrator -- Directs --> Coder\n",
    "        Orchestrator -- Directs --> ComputerTerminal\n",
    "    end\n",
    "\n",
    "    Terminate --> Review[\"Review & Final Report\"]\n",
    "    OuterLoop --> Agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code adaptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following expanded code structure integrates each part of the **Magnetic-One Multi-Agent System** workflow, ensuring that the Orchestrator manages agents within an inner/outer loop, assigns agents to prevent stalls, and generates a comprehensive final report based on the Task Ledger.\n",
    "\n",
    "This code an intent to perform **Magnetic-One** workflow based on **LangGraph**, it's the version 0.0.1 and still need refinement and testing. **Agents may need tool calling**, it's suggested to create such tools by following: [Creating tools with Hierarchical Agent Teams](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/hierarchical_agent_teams.ipynb) and then adjust the code by alligning those tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Libraries, Setup, and Initialization\n",
    "\n",
    "Defining the required imports, classes, and initial setup based on `LangGraph`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraphNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading langgraph-0.2.48-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain_experimental\n",
      "  Downloading langchain_experimental-0.3.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 (from langgraph)\n",
      "  Downloading langchain_core-0.3.18-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.4-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.32 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.36-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.11.2-cp310-cp310-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.143-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting openai<2.0.0,>=1.54.0 (from langchain_openai)\n",
      "  Downloading openai-1.54.4-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Using cached tiktoken-0.8.0-cp310-cp310-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain_experimental)\n",
      "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached propcache-0.2.0-cp310-cp310-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.17.1-cp310-cp310-win_amd64.whl.metadata (66 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Using cached SQLAlchemy-2.0.35-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\dropbox\\ai\\clonedrepis\\magnetic-one-langgraph\\.conda\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\dropbox\\ai\\clonedrepis\\magnetic-one-langgraph\\.conda\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph)\n",
      "  Using cached msgpack-1.1.0-cp310-cp310-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
      "  Downloading orjson-3.10.11-cp310-none-win_amd64.whl.metadata (52 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.54.0->langchain_openai)\n",
      "  Using cached anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.54.0->langchain_openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.54.0->langchain_openai)\n",
      "  Downloading jiter-0.7.1-cp310-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.54.0->langchain_openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.54.0->langchain_openai)\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Using cached pydantic_core-2.23.4-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Using cached charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Using cached greenlet-3.1.1-cp310-cp310-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\dropbox\\ai\\clonedrepis\\magnetic-one-langgraph\\.conda\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.2.2)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: colorama in e:\\dropbox\\ai\\clonedrepis\\magnetic-one-langgraph\\.conda\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.54.0->langchain_openai) (0.4.6)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langgraph-0.2.48-py3-none-any.whl (124 kB)\n",
      "Downloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 0.8/1.0 MB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 251.8 kB/s eta 0:00:00\n",
      "Downloading langchain_openai-0.2.8-py3-none-any.whl (50 kB)\n",
      "Downloading langchain_experimental-0.3.3-py3-none-any.whl (208 kB)\n",
      "Downloading aiohttp-3.11.2-cp310-cp310-win_amd64.whl (440 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.4/2.4 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 568.7 kB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.18-py3-none-any.whl (409 kB)\n",
      "Downloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_checkpoint-2.0.4-py3-none-any.whl (23 kB)\n",
      "Downloading langgraph_sdk-0.1.36-py3-none-any.whl (29 kB)\n",
      "Downloading langsmith-0.1.143-py3-none-any.whl (306 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-win_amd64.whl (15.8 MB)\n",
      "Downloading openai-1.54.4-py3-none-any.whl (389 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp310-none-win_amd64.whl (1.9 MB)\n",
      "Using cached PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached SQLAlchemy-2.0.35-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.8.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "Using cached greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jiter-0.7.1-cp310-none-win_amd64.whl (201 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached msgpack-1.1.0-cp310-cp310-win_amd64.whl (74 kB)\n",
      "Using cached multidict-6.1.0-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.11-cp310-none-win_amd64.whl (136 kB)\n",
      "Using cached propcache-0.2.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "Downloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yarl-1.17.1-cp310-cp310-win_amd64.whl (89 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, tqdm, tenacity, sniffio, regex, PyYAML, python-dotenv, pydantic-core, propcache, orjson, numpy, mypy-extensions, multidict, msgpack, marshmallow, jsonpointer, jiter, idna, httpx-sse, h11, greenlet, frozenlist, distro, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, tiktoken, requests-toolbelt, pydantic-settings, httpx, dataclasses-json, aiohttp, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain_openai, langgraph, langchain, langchain-community, langchain_experimental\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.35 aiohappyeyeballs-2.4.3 aiohttp-3.11.2 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.2.post1 async-timeout-4.0.3 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 dataclasses-json-0.6.7 distro-1.9.0 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 httpx-sse-0.4.0 idna-3.10 jiter-0.7.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.7 langchain-community-0.3.7 langchain-core-0.3.18 langchain-text-splitters-0.3.2 langchain_experimental-0.3.3 langchain_openai-0.2.8 langgraph-0.2.48 langgraph-checkpoint-2.0.4 langgraph-sdk-0.1.36 langsmith-0.1.143 marshmallow-3.23.1 msgpack-1.1.0 multidict-6.1.0 mypy-extensions-1.0.0 numpy-1.26.4 openai-1.54.4 orjson-3.10.11 propcache-0.2.0 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.6.1 python-dotenv-1.0.1 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 tiktoken-0.8.0 tqdm-4.67.0 typing-inspect-0.9.0 urllib3-2.2.3 yarl-1.17.1\n",
      "Collecting pydantic==2.0\n",
      "  Using cached pydantic-2.0-py3-none-any.whl.metadata (117 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in e:\\dropbox\\ai\\clonedrepis\\magnetic-one-langgraph\\.conda\\lib\\site-packages (from pydantic==2.0) (0.7.0)\n",
      "Collecting pydantic-core==2.0.1 (from pydantic==2.0)\n",
      "  Using cached pydantic_core-2.0.1-cp310-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\dropbox\\ai\\clonedrepis\\magnetic-one-langgraph\\.conda\\lib\\site-packages (from pydantic==2.0) (4.12.2)\n",
      "Using cached pydantic-2.0-py3-none-any.whl (355 kB)\n",
      "Using cached pydantic_core-2.0.1-cp310-none-win_amd64.whl (1.5 MB)\n",
      "Installing collected packages: pydantic-core, pydantic\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.23.4\n",
      "    Uninstalling pydantic_core-2.23.4:\n",
      "      Successfully uninstalled pydantic_core-2.23.4\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.9.2\n",
      "    Uninstalling pydantic-2.9.2:\n",
      "      Successfully uninstalled pydantic-2.9.2\n",
      "Successfully installed pydantic-2.0 pydantic-core-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.7 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 2.0 which is incompatible.\n",
      "langchain-core 0.3.18 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 2.0 which is incompatible.\n",
      "pydantic-settings 2.6.1 requires pydantic>=2.7.0, but you have pydantic 2.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# install our required packages and set our API keys\n",
    "# %%capture --no-stderr\n",
    "# %pip install -U langgraph langchain langchain_openai langchain_experimental\n",
    "# !pip install pydantic==2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.10.15)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'e:/Dropbox/AI/clonedRepis/magnetic-one-langgraph/.venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'langchain_core.runnables.base.RunnableEachBase'> is not a generic class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m END, START, StateGraph, MessagesState\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict, List, Tuple, Optional\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\langgraph\\graph\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m END, START, Graph\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessageGraph, MessagesState, add_messages\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StateGraph\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\langgraph\\graph\\graph.py:21\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     Any,\n\u001b[0;32m      6\u001b[0m     Awaitable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     overload,\n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Runnable\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableLike\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableConfig\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain_core\\runnables\\__init__.py:20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"LangChain **Runnable** and the **LangChain Expression Language (LCEL)**.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mThe LangChain Expression Language (LCEL) offers a declarative method to build\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains schema and implementation of LangChain Runnables primitives.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     21\u001b[0m     Runnable,\n\u001b[0;32m     22\u001b[0m     RunnableBinding,\n\u001b[0;32m     23\u001b[0m     RunnableGenerator,\n\u001b[0;32m     24\u001b[0m     RunnableLambda,\n\u001b[0;32m     25\u001b[0m     RunnableMap,\n\u001b[0;32m     26\u001b[0m     RunnableParallel,\n\u001b[0;32m     27\u001b[0m     RunnableSequence,\n\u001b[0;32m     28\u001b[0m     RunnableSerializable,\n\u001b[0;32m     29\u001b[0m     chain,\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbranch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RunnableBranch\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     RunnableConfig,\n\u001b[0;32m     34\u001b[0m     ensure_config,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     run_in_executor,\n\u001b[0;32m     38\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\langchain_core\\runnables\\base.py:5087\u001b[0m\n\u001b[0;32m   5083\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[0;32m   5084\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m-> 5087\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRunnableEach\u001b[39;00m(\u001b[43mRunnableEachBase\u001b[49m\u001b[43m[\u001b[49m\u001b[43mInput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOutput\u001b[49m\u001b[43m]\u001b[49m):\n\u001b[0;32m   5088\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runnable that delegates calls to another Runnable\u001b[39;00m\n\u001b[0;32m   5089\u001b[0m \u001b[38;5;124;03m    with each element of the input sequence.\u001b[39;00m\n\u001b[0;32m   5090\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5112\u001b[0m \u001b[38;5;124;03m            print(output)  # noqa: T201\u001b[39;00m\n\u001b[0;32m   5113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   5115\u001b[0m     \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   5116\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_lc_namespace\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\pydantic\\main.py:591\u001b[0m, in \u001b[0;36mBaseModel.__class_getitem__\u001b[1;34m(cls, typevar_values)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be parametrized because it does not inherit from typing.Generic\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_generic_metadata__[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m typing\u001b[38;5;241m.\u001b[39mGeneric \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m:\n\u001b[1;32m--> 591\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a generic class\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(typevar_values, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    594\u001b[0m     typevar_values \u001b[38;5;241m=\u001b[39m (typevar_values,)\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'langchain_core.runnables.base.RunnableEachBase'> is not a generic class"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# Initialize OpenAI model for language processing\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Define Task State Structure\n",
    "class TaskState:\n",
    "    \"\"\"\n",
    "    Define the task state structure, including Task Ledger, plan, counter, and result summary.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.messages: List[str] = []\n",
    "        self.task_ledger: Dict[str, str] = {}    # Task Ledger for facts, guesses, etc.\n",
    "        self.task_plan: List[Tuple[str, str]] = []  # Step-by-step task plan\n",
    "        self.counter: int = 0                    # Counter to detect stalls\n",
    "        self.final_report: Optional[str] = None  # Stores the final report summary\n",
    "        self.task_complete: bool = False         # Completion status\n",
    "#    The inner loop continues until the Orchestrator determines the task is complete or hits a predefined stopping criterion (e.g., maximum attempts or time limits).\n",
    "    def update_task_ledger(self, key: str, value: str):\n",
    "        self.task_ledger[key] = value\n",
    "\n",
    "    def increment_counter(self):\n",
    "        self.counter += 1\n",
    "\n",
    "    def reset_counter(self):\n",
    "        self.counter = 0\n",
    "\n",
    "    def set_task_complete(self, status: bool = True):\n",
    "        self.task_complete = status\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Orchestrator and Inner/Outer Loop\n",
    "\n",
    "The **Orchestrator** will serve as the central agent, managing task setup, ledger updates, plan formation, and calling agents. I'll implement this with additional helper functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator_agent(state: TaskState):\n",
    "    \"\"\"\n",
    "    Initializes the Task Ledger, sets up a plan, and manages agent selection.\n",
    "    \"\"\"\n",
    "    state.task_ledger = create_task_ledger()\n",
    "    state.task_plan = generate_task_plan(state)\n",
    "    state.messages.append(\"Orchestrator has set up the task and plan.\")\n",
    "    return state\n",
    "\n",
    "def create_task_ledger() -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Populates the Task Ledger with initial facts and guesses.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"task_id\": \"001\",\n",
    "        \"known_facts\": \"Initial task facts\",\n",
    "        \"guesses\": \"Potential unknown elements\"\n",
    "    }\n",
    "\n",
    "def generate_task_plan(state: TaskState) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Generates a task plan based on the Task Ledger.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        (\"WebSurfer\", \"Perform web search\"),\n",
    "        (\"FileSurfer\", \"Read from files\"),\n",
    "        (\"Coder\", \"Analyze data\"),\n",
    "        (\"ComputerTerminal\", \"Execute necessary commands\"),\n",
    "    ]\n",
    "\n",
    "def assign_next_agent(state: TaskState):\n",
    "    \"\"\"\n",
    "    Assigns the next agent based on progress or stall detection.\n",
    "    \"\"\"\n",
    "    if state.task_complete:\n",
    "        return \"Complete\"\n",
    "\n",
    "    if state.counter >= 2:  # Counter threshold for stalls\n",
    "        state.messages.append(\"Orchestrator reflecting due to stall.\")\n",
    "        reflect_and_adjust(state)\n",
    "        state.reset_counter()\n",
    "    else:\n",
    "        state.increment_counter()\n",
    "\n",
    "    if state.task_plan:\n",
    "        next_task = state.task_plan.pop(0)\n",
    "        state.reset_counter()\n",
    "        return next_task\n",
    "    else:\n",
    "        return \"Reflect and Adjust\"\n",
    "\n",
    "def reflect_and_adjust(state: TaskState):\n",
    "    \"\"\"\n",
    "    Revisits the Task Ledger and redefines the task plan if stalls are detected.\n",
    "    \"\"\"\n",
    "    state.messages.append(\"Revisiting task plan and refining approach.\")\n",
    "    # Modify the task plan based on current state as a demonstration\n",
    "    state.task_plan = [(\"WebSurfer\", \"Re-attempt web search\"), (\"FileSurfer\", \"Re-check files\")]\n",
    "\n",
    "def evaluate_completion(state: TaskState) -> bool:\n",
    "    \"\"\"\n",
    "    Determines if the task is complete based on criteria in the Task Ledger.\n",
    "    \"\"\"\n",
    "    return \"web_data\" in state.task_ledger and \"file_data\" in state.task_ledger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Specialized Agents for Task Execution\n",
    "\n",
    "Each agent will be tasked with specific actions, such as web scraping, reading files, or code analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_surfer_agent(state: TaskState):\n",
    "    \"\"\"\n",
    "    Gathers data from the web and updates Task Ledger.\n",
    "    \"\"\"\n",
    "    state.messages.append(\"WebSurfer is gathering data from the web.\")\n",
    "    state.task_ledger[\"web_data\"] = \"Sample web data retrieved\"\n",
    "    return state\n",
    "\n",
    "def file_surfer_agent(state: TaskState):\n",
    "    \"\"\"\n",
    "    Reads files and updates Task Ledger.\n",
    "    \"\"\"\n",
    "    state.messages.append(\"FileSurfer is reading files.\")\n",
    "    state.task_ledger[\"file_data\"] = \"Sample file data retrieved\"\n",
    "    return state\n",
    "\n",
    "def coder_agent(state: TaskState):\n",
    "    \"\"\"\n",
    "    Analyzes or debugs code as required by the task.\n",
    "    \"\"\"\n",
    "    state.messages.append(\"Coder is analyzing code.\")\n",
    "    state.task_ledger[\"code_analysis\"] = \"Code analyzed successfully.\"\n",
    "    return state\n",
    "\n",
    "def computer_terminal_agent(state: TaskState):\n",
    "    \"\"\"\n",
    "    Executes necessary commands or installs libraries.\n",
    "    \"\"\"\n",
    "    state.messages.append(\"ComputerTerminal is executing commands.\")\n",
    "    state.task_ledger[\"execution_result\"] = \"Commands executed successfully.\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Final Reporting and Termination\n",
    "\n",
    "The final report will summarize the gathered information and results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_task(state: TaskState):\n",
    "    \"\"\"\n",
    "    Generates a final report based on the Task Ledger.\n",
    "    \"\"\"\n",
    "    state.final_report = (\n",
    "        f\"Task ID: {state.task_ledger.get('task_id')}\\n\"\n",
    "        f\"Known Facts: {state.task_ledger.get('known_facts')}\\n\"\n",
    "        f\"Web Data: {state.task_ledger.get('web_data')}\\n\"\n",
    "        f\"File Data: {state.task_ledger.get('file_data')}\\n\"\n",
    "        f\"Code Analysis: {state.task_ledger.get('code_analysis')}\\n\"\n",
    "        f\"Execution Result: {state.task_ledger.get('execution_result')}\\n\"\n",
    "        f\"Uncertainties: {state.task_ledger.get('guesses')}\\n\"\n",
    "    )\n",
    "    state.messages.append(\"Final report generated.\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Workflow Graph Definition\n",
    "\n",
    "Creating the workflow graph by defining nodes and transitions based on the above agent functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the task execution graph\n",
    "graph = StateGraph(TaskState)\n",
    "\n",
    "# Add nodes (agents and orchestrator) to the graph\n",
    "graph.add_node(\"Orchestrator\", orchestrator_agent)\n",
    "graph.add_node(\"WebSurfer\", web_surfer_agent)\n",
    "graph.add_node(\"FileSurfer\", file_surfer_agent)\n",
    "graph.add_node(\"Coder\", coder_agent)\n",
    "graph.add_node(\"ComputerTerminal\", computer_terminal_agent)\n",
    "graph.add_node(\"FinalReview\", finalize_task)\n",
    "\n",
    "# Define transitions\n",
    "graph.add_edge(\"Orchestrator\", \"WebSurfer\")        # Start with web data gathering\n",
    "graph.add_edge(\"WebSurfer\", \"FileSurfer\")          # Move to file reading\n",
    "graph.add_edge(\"FileSurfer\", \"Coder\")              # Move to code analysis\n",
    "graph.add_edge(\"Coder\", \"ComputerTerminal\")        # Move to terminal execution\n",
    "graph.add_edge(\"ComputerTerminal\", \"FinalReview\")  # Final review after all steps\n",
    "\n",
    "# Add start and end nodes\n",
    "graph.add_edge(START, \"Orchestrator\")              # Initial task setup by orchestrator\n",
    "graph.add_edge(\"FinalReview\", END)                 # End after final review\n",
    "\n",
    "# Compile the graph\n",
    "compiled_graph = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6. Execution Flow Function\n",
    "\n",
    "This function will run the task system, beginning from the initial task description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidUpdateError",
     "evalue": "Must write to at least one of []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidUpdateError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run the task system with an example description\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mrun_task_system\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAnalyze new market trends and compile a report.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m, in \u001b[0;36mrun_task_system\u001b[1;34m(task_description)\u001b[0m\n\u001b[0;32m      5\u001b[0m task_state \u001b[38;5;241m=\u001b[39m TaskState()\n\u001b[0;32m      6\u001b[0m task_state\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask started: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_description\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m compiled_graph\u001b[38;5;241m.\u001b[39mstream(task_state):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__end__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m state:\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(state\u001b[38;5;241m.\u001b[39mmessages[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1273\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1268\u001b[0m         input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels,\n\u001b[0;32m   1269\u001b[0m         interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before_,\n\u001b[0;32m   1270\u001b[0m         interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after_,\n\u001b[0;32m   1271\u001b[0m         manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1272\u001b[0m     ):\n\u001b[1;32m-> 1273\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1274\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1275\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1276\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1277\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1278\u001b[0m         ):\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\langgraph\\pregel\\runner.py:56\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m     54\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\langgraph\\pregel\\retry.py:29\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy)\u001b[0m\n\u001b[0;32m     27\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\langgraph\\utils\\runnable.py:176\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m    175\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m--> 176\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    178\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\langgraph\\pregel\\write.py:85\u001b[0m, in \u001b[0;36mChannelWrite._write\u001b[1;34m(self, input, config)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Any, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     writes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     80\u001b[0m         ChannelWriteEntry(write\u001b[38;5;241m.\u001b[39mchannel, \u001b[38;5;28minput\u001b[39m, write\u001b[38;5;241m.\u001b[39mskip_none, write\u001b[38;5;241m.\u001b[39mmapper)\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(write, ChannelWriteEntry) \u001b[38;5;129;01mand\u001b[39;00m write\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m PASSTHROUGH\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m write\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m write \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrites\n\u001b[0;32m     84\u001b[0m     ]\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_at_least_one_of\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\isultan\\AppData\\Local\\anaconda3\\envs\\py310\\lib\\site-packages\\langgraph\\pregel\\write.py:138\u001b[0m, in \u001b[0;36mChannelWrite.do_write\u001b[1;34m(config, writes, require_at_least_one_of)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m require_at_least_one_of \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m {chan \u001b[38;5;28;01mfor\u001b[39;00m chan, _ \u001b[38;5;129;01min\u001b[39;00m filtered} \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mset\u001b[39m(require_at_least_one_of):\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidUpdateError(\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust write to at least one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequire_at_least_one_of\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         )\n\u001b[0;32m    141\u001b[0m write: TYPE_SEND \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_SEND]\n\u001b[0;32m    142\u001b[0m write(sends \u001b[38;5;241m+\u001b[39m filtered)\n",
      "\u001b[1;31mInvalidUpdateError\u001b[0m: Must write to at least one of []"
     ]
    }
   ],
   "source": [
    "def run_task_system(task_description: str):\n",
    "    \"\"\"\n",
    "    Execute the task system starting from the initial description.\n",
    "    \"\"\"\n",
    "    task_state = TaskState()\n",
    "    task_state.messages.append(f\"Task started: {task_description}\")\n",
    "\n",
    "    for state in compiled_graph.stream(task_state):\n",
    "        if \"__end__\" not in state:\n",
    "            print(state.messages[-1])\n",
    "        else:\n",
    "            print(\"Task Complete\")\n",
    "            print(state.final_report)\n",
    "            break\n",
    "\n",
    "# Run the task system with an example description\n",
    "run_task_system(\"Analyze new market trends and compile a report.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
